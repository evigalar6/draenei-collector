from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.utils.dates import days_ago
from datetime import timedelta
import time
import random


# Ğ†Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸ Ñ‚Ğ²Ğ¾Ñ—Ñ… Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ–Ğ²
from collector.scraper import scrape_draenei_metadata
from uploader.s3_manager import S3Manager

# --- ĞĞ°Ğ»Ğ°ÑˆÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ DAG ---
default_args = {
    'owner': 'evi',
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
        dag_id='draenei_content_loader_v3_fixed',  # Ğ—Ğ¼Ñ–Ğ½Ğ¸Ğ² ID, Ñ‰Ğ¾Ğ± Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¾Ğ½Ğ¾Ğ²Ğ¸Ğ»Ğ¾ÑÑ
        default_args=default_args,
        description='ETL pipeline: Wallhaven -> Postgres -> S3',
        schedule_interval='@daily',
        start_date=days_ago(1),
        catchup=False,
        tags=['draenei', 'portfolio'],
) as dag:
    # --- STEP 1: EXTRACT ---
    # 1. Ğ¡Ğ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºÑƒ Ğ²Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ñ”Ğ¼Ğ¾ Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ
    def extract_data(**kwargs):
        # ĞœĞ¾Ğ¶ĞµÑˆ Ğ·Ğ¼Ñ–Ğ½Ğ¸Ñ‚Ğ¸ limit=10, Ñ‰Ğ¾Ğ± ĞºĞ°Ñ‡Ğ°Ñ‚Ğ¸ Ğ±Ñ–Ğ»ÑŒÑˆĞµ
        random_page = random.randint(1, 2)
        print(f"ğŸ² Ğ¢ÑĞ³Ğ½ĞµĞ¼Ğ¾ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºÑƒ â„–{random_page}")
        data = scrape_draenei_metadata(query="draenei", limit=10, page=random_page)
        return data


    # 2. ĞŸĞ¾Ñ‚Ñ–Ğ¼ ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ Ñ‚Ğ°ÑĞº
    task_extract = PythonOperator(
        task_id='extract_metadata',
        python_callable=extract_data,
    )


    # --- STEP 2: LOAD METADATA ---
    # 1. Ğ¡Ğ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºÑƒ Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ!
    def load_metadata_to_db(ti):
        metadata_list = ti.xcom_pull(task_ids='extract_metadata')

        if not metadata_list:
            print("âš ï¸ Ğ”Ğ°Ğ½Ğ¸Ñ… Ğ½ĞµĞ¼Ğ°Ñ”. ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ”Ğ¼Ğ¾.")
            return

        pg_hook = PostgresHook(postgres_conn_id='postgres_default')

        insert_query = """
            INSERT INTO draenei_content.wallpapers 
            (wallhaven_id, url, resolution, category, purity, file_size)
            VALUES (%s, %s, %s, %s, %s, %s)
            ON CONFLICT (wallhaven_id) DO NOTHING;
        """

        rows_to_insert = []
        for item in metadata_list:
            rows_to_insert.append((
                item['wallhaven_id'],
                item['url'],
                item['resolution'],
                item['category'],
                item['purity'],
                item['file_size']
            ))

        connection = pg_hook.get_conn()
        cursor = connection.cursor()
        cursor.executemany(insert_query, rows_to_insert)
        connection.commit()
        cursor.close()
        connection.close()
        print(f"âœ… Ğ’ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ {len(rows_to_insert)} Ğ·Ğ°Ğ¿Ğ¸ÑÑ–Ğ².")


    # 2. ĞŸĞ¾Ñ‚Ñ–Ğ¼ Ñ‚Ğ°ÑĞº (Ñ‚ÑƒÑ‚ Ğ±ÑƒĞ»Ğ° Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ°)
    task_load_db = PythonOperator(
        task_id='load_metadata_to_db',
        python_callable=load_metadata_to_db,  # Python ÑˆÑƒĞºĞ°Ñ” Ñ†Ñ Ğ½Ğ°Ğ·Ğ²Ñƒ Ğ’Ğ˜Ğ©Ğ• Ğ¿Ğ¾ ĞºĞ¾Ğ´Ñƒ
    )


    # --- STEP 3: UPLOAD TO S3 ---
    # 1. Ğ¡Ğ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºÑƒ Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ!
    def download_and_upload_images():
        manager = S3Manager()
        pg_hook = PostgresHook(postgres_conn_id='postgres_default')

        # Ğ‘ĞµÑ€ĞµĞ¼Ğ¾ 5 ÑˆÑ‚ÑƒĞº Ğ·Ğ° Ñ€Ğ°Ğ·
        records = pg_hook.get_records("""
            SELECT id, url, wallhaven_id FROM draenei_content.wallpapers 
            WHERE s3_key IS NULL
            LIMIT 5;
        """)

        print(f"ğŸ“¦ Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(records)} ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½Ğ¾Ğº Ğ´Ğ»Ñ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ.")

        for row in records:
            db_id, image_url, wall_id = row
            print(f"â¬‡ï¸ ĞšĞ°Ñ‡Ğ°Ñ ID {db_id}: {image_url}")

            file_bytes = manager.download_image_as_bytes(image_url)

            if file_bytes:
                ext = image_url.split('.')[-1] if '.' in image_url else 'jpg'
                s3_key = f"wallpapers/{wall_id}.{ext}"

                if manager.upload_file(file_bytes, s3_key):
                    sql_update = """
                        UPDATE draenei_content.wallpapers 
                        SET s3_key = %s, updated_at = NOW() 
                        WHERE id = %s;
                    """
                    pg_hook.run(sql_update, parameters=(s3_key, db_id))
                    print(f"âœ¨ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾: {s3_key}")
                else:
                    print(f"âš ï¸ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° S3 Ğ´Ğ»Ñ {db_id}")

            time.sleep(1)


    # 2. ĞŸĞ¾Ñ‚Ñ–Ğ¼ Ñ‚Ğ°ÑĞº
    task_upload_s3 = PythonOperator(
        task_id='download_and_upload_to_s3',
        python_callable=download_and_upload_images,
    )

    # --- ĞŸĞ¾Ñ€ÑĞ´Ğ¾Ğº ---
    task_extract >> task_load_db >> task_upload_s3